{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bcda493",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "In the following block we are just importing the main libraries used for creating a NN and processing its output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d89f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from models.binarized_modules import  BinarizeLinear,BinarizeConv2d\n",
    "from models.binarized_modules import  Binarize,HingeLoss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85a310",
   "metadata": {},
   "source": [
    "# Load MNIST\n",
    "\n",
    "In the incoming block the MNIST dataset is created and loaded to the standard DataLoader of pytorch. This allow to simply call train_data and test_data when training the network without having to manually create the batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13219a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdTransform(object):\n",
    "    def __init__(self, thr_255):\n",
    "        self.thr = thr_255   # input threshold for [0..255] gray level, convert to [0..1]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return (x >= self.thr).to(x.dtype)  # do not change the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76648145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocessing data: convert to tensors and normalize by subtracting dataset\n",
    "# mean and dividing by std.\n",
    "# We need to recall that the data is normalized when doing the ASIC implementation \n",
    "# The dummy input we feed in the ASIC must be normalized as well \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                ThresholdTransform(thr_255=0)])\n",
    "\n",
    "# Get data from torchvision.datasets\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# Define data loaders used to iterate through dataset\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data)\n",
    "\n",
    "# Show some example images and the associated label to verify that the data is loaded correctly \n",
    "\n",
    "labels_map = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9 Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 10, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c37c7",
   "metadata": {},
   "source": [
    "# MNIST classification with Binary Neural Network\n",
    "## Sign function \n",
    "The function implemented below is the sign() function mentioned in the paper. However, this function is not used for training as it would not allow for gradient descent calculation. The idea is to use this function after the train has been performed (TODO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859b14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sign(a):\n",
    "    \n",
    "    a_buff = torch.empty(a.shape)\n",
    "    for idx, element in enumerate(a):\n",
    "        for idy, sub_element in enumerate(element):\n",
    "            if(sub_element >= 0):\n",
    "                a_buff[idx][idy] = 1\n",
    "            else:\n",
    "                a_buff[idx][idy] = -1\n",
    "            \n",
    "    return a_buff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33abfde",
   "metadata": {},
   "source": [
    "## Create a class for the pytorch BNN\n",
    "Here I am basically creating my own definition of the network, the __init__ is the constructor and creates the class instances of the layer I want to use. The foreward function instead, perform the foreward pass of the network based on the order on which I put the layers previously created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7840a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_BNN(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch neural network. Network layers are defined in __init__ and forward\n",
    "    pass implemented in forward.\n",
    "    \n",
    "    Args:\n",
    "        in_features: number of features in input layer\n",
    "        hidden_dim: number of features in hidden dimension\n",
    "        out_features: number of features in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(MY_BNN, self).__init__()\n",
    "        self.fc1 = BinarizeLinear(in_features, hidden_dim, bias = False)\n",
    "        self.htanh1 = nn.Hardtanh()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.htanh2 = nn.Hardtanh()\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.htanh3 = nn.Hardtanh()\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc4 = BinarizeLinear(hidden_dim, out_features, bias = False)\n",
    "        self.drop=nn.Dropout(0.25)\n",
    "        self.logsoftmax=nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)    \n",
    "        x = self.bn1(x)    \n",
    "        x = self.htanh1(x) \n",
    "        x = self.fc2(x)    \n",
    "        x = self.bn2(x)    \n",
    "        x = self.htanh2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.htanh3(x)\n",
    "        x = self.fc4(x)\n",
    "        return self.logsoftmax(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f218dfe",
   "metadata": {},
   "source": [
    "## Initialize parameters and criterion of the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23336d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bytes required 0.0125 Mbyte\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pytorch network\n",
    "\n",
    "in_features = 28*28 # this is because the input image is flatten into and array of 28*28, 28 being the number of pixels\n",
    "hidden_dim = 100 # number of neurons in an hidden layer\n",
    "hidden_layers = 2\n",
    "out_features = 10 # we need to classify 10 classes of number 0 to 10 \n",
    "learning_rate = 0.003 # this is the step that we take to move in the direction of the gradient \n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Meaning that we use cross entropy as a loss function \n",
    "epochs = 10 # number of times we are going across the full dataset \n",
    "\n",
    "\n",
    "\n",
    "model = MY_BNN(in_features, hidden_dim, out_features)\n",
    "\n",
    "#find number of param \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of bytes required\",pytorch_total_params /8/1e6 , \"Mbyte\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate) # Adam algorithm to optimize change of learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e9e8b",
   "metadata": {},
   "source": [
    "## Definition of the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e4ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []  # hold the loss for each batch -> used to display training afterwards \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_losses.append(loss)\n",
    "\n",
    "        if epoch%40==0:\n",
    "            optimizer.param_groups[0]['lr']=optimizer.param_groups[0]['lr']*0.1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "        optimizer.step()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "                \n",
    "        #print(output)\n",
    "        #print(target)\n",
    "       # correct = torch.argmax(output, axis=1) == torch.argmax(target, axis=1)\n",
    "        #train_accs.append(torch.sum(correct)/len(y_pred))\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.bn2.weight\n",
    "for p in list(model.parameters()):\n",
    "    print(p.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5775fe",
   "metadata": {},
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fbbd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/j0yzvf055y7c23h6ltl5b3pr0000gn/T/ipykernel_52016/3942372170.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.logsoftmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 15.573915\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 3.821992\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.782306\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.239111\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 3.106381\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.193875\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 3.205960\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.664849\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.151680\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 3.021485\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.770953\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.728903\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.401958\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.204364\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.586478\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.863111\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.951960\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.789486\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 3.299883\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.234813\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 3.236437\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.718390\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.327024\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.108549\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.827972\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.407754\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.604593\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.281798\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.828198\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.754751\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.442502\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.884668\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 3.270863\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.617486\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.607480\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.614563\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.402169\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.654623\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.721495\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.292555\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.841137\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.887927\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.572851\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.916729\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.915620\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 2.511519\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.558586\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.363870\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.247154\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 2.305562\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.520537\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 1.813614\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.796628\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 1.053677\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.415845\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.546409\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 2.994746\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 2.194140\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.783938\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.097357\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.518151\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 1.021749\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.392770\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.846306\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.880368\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.192068\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 2.088560\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 1.923751\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.769533\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.923376\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.919514\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 3.320444\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.305079\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.321743\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.345632\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.454591\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.389778\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 1.993006\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.422424\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.790053\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.795383\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 1.855672\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.640889\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.908323\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.943792\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.537892\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.561622\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.888939\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.200978\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.550786\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.295721\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.729053\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.768342\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 2.270122\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 3.349134\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.965662\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.995137\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.886044\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.783261\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 2.725491\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f06a4",
   "metadata": {},
   "source": [
    "## Display loss vs iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d16dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new = []\n",
    "for element in train_losses:\n",
    "    new.append(element.detach().numpy())\n",
    "    \n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(new)\n",
    "plt.grid()\n",
    "plt.savefig('foo.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b874b15",
   "metadata": {},
   "source": [
    "## Define a function for testing the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c8727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "       \n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d854a31",
   "metadata": {},
   "source": [
    "## Test it\n",
    "After this section the accuracy of the trained network will be printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f978be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/j0yzvf055y7c23h6ltl5b3pr0000gn/T/ipykernel_52016/3942372170.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.logsoftmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.0760, Accuracy: 9351/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf9a8a",
   "metadata": {},
   "source": [
    "## Test a single prediction after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_data[11]\n",
    "print(label)\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "output = model(img)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93d47a",
   "metadata": {},
   "source": [
    "## Printing the weights\n",
    "This section must be refined to make sure that I am able to print the weight for each layer in a proper manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea45a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc2.weight)\n",
    "print(model.fc2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight)\n",
    "print(model.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight.shape)\n",
    "print(model.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ac8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc4.weight)\n",
    "print(model.fc4.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb91a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.bn1.weight)\n",
    "print(model.fc4.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf49ab4",
   "metadata": {},
   "source": [
    "## Save network weights in a csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98aec9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First convert all network layers into numpy \n",
    "numpy_fc1 = model.fc1.weight.data.cpu().detach().numpy()\n",
    "numpy_fc2 = model.fc2.weight.data.cpu().detach().numpy()\n",
    "numpy_fc3 = model.fc3.weight.data.cpu().detach().numpy()\n",
    "numpy_fc4 = model.fc4.weight.data.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "#Convert numpy to pandas dataframe \n",
    "df_fc1 = pd.DataFrame(numpy_fc1)\n",
    "df_fc2 = pd.DataFrame(numpy_fc2)\n",
    "df_fc3 = pd.DataFrame(numpy_fc3)\n",
    "df_fc4 = pd.DataFrame(numpy_fc4)\n",
    "\n",
    "\n",
    "#Export to csv with pandas \n",
    "df_fc1.to_csv('W_fc1.csv',index=False,header=False)\n",
    "df_fc2.to_csv('W_fc2.csv',index=False,header=False)\n",
    "df_fc3.to_csv('W_fc3.csv',index=False,header=False)\n",
    "df_fc4.to_csv('W_fc4.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c9721",
   "metadata": {},
   "source": [
    "# Test binarized\n",
    "I know want to test if the network still infers correctly if I have the sign instead of the hardtanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9e9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_BNN_test(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch neural network. Network layers are defined in __init__ and forward\n",
    "    pass implemented in forward.\n",
    "    \n",
    "    Args:\n",
    "        in_features: number of features in input layer\n",
    "        hidden_dim: number of features in hidden dimension\n",
    "        out_features: number of features in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(MY_BNN_test, self).__init__()\n",
    "\n",
    "        self.fc1 = BinarizeLinear(in_features, hidden_dim, bias = False)\n",
    "        self.fc2 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc3 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc4 = BinarizeLinear(hidden_dim, out_features, bias = False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sign(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.sign(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sign(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea60ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = MY_BNN_test(in_features, hidden_dim, out_features)\n",
    "model_test.fc1.weight = model.fc1.weight\n",
    "model_test.fc2.weight = model.fc2.weight\n",
    "model_test.fc3.weight = model.fc3.weight\n",
    "model_test.fc4.weight = model.fc4.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c23a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([10, 100])\n"
     ]
    }
   ],
   "source": [
    "print(model_test.fc1.weight.shape)\n",
    "print(model_test.fc2.weight.shape)\n",
    "print(model_test.fc3.weight.shape)\n",
    "print(model_test.fc4.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "470d7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_test():\n",
    "    model_test.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model_test(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fb36477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 3.7854, Accuracy: 7316/10000 (73%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a49f3",
   "metadata": {},
   "source": [
    "# Testing that outputs are binarized values at each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96c7f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a model that prints the output tensor at each stage \n",
    "\n",
    "\n",
    "\n",
    "class MY_BNN_test_printer(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch neural network. Network layers are defined in __init__ and forward\n",
    "    pass implemented in forward.\n",
    "    \n",
    "    Args:\n",
    "        in_features: number of features in input layer\n",
    "        hidden_dim: number of features in hidden dimension\n",
    "        out_features: number of features in output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(MY_BNN_test_printer, self).__init__()\n",
    "\n",
    "        self.fc1 = BinarizeLinear(in_features, hidden_dim, bias = False)\n",
    "        self.fc2 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc3 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc4 = BinarizeLinear(hidden_dim, out_features, bias = False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        global flatten_x,fc1_out,signed_fc1_out,fc2_out,signed_fc2_out,fc3_out,signed_fc3_out,fc4_out\n",
    "        x = x.view(-1, 28*28)\n",
    "        flatten_x = x\n",
    "        x = self.fc1(x)\n",
    "        fc1_out = x\n",
    "        x = my_sign(x)\n",
    "        signed_fc1_out = x\n",
    "        x = self.fc2(x)\n",
    "        fc2_out = x\n",
    "        x = my_sign(x)\n",
    "        signed_fc2_out = x\n",
    "        x = self.fc3(x)\n",
    "        fc3_out = x\n",
    "        x = my_sign(x)\n",
    "        signed_fc3_out = x\n",
    "        x = self.fc4(x)\n",
    "        fc4_out = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "411c65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_printer = MY_BNN_test_printer(in_features, hidden_dim, out_features)\n",
    "model_test_printer.fc1.weight = model.fc1.weight\n",
    "model_test_printer.fc2.weight = model.fc2.weight\n",
    "model_test_printer.fc3.weight = model.fc3.weight\n",
    "model_test_printer.fc4.weight = model.fc4.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9607eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_test_printer.fc1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e780707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([[2]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#just getting one image to feed in the network\n",
    "\n",
    "img, label = test_data[1]\n",
    "print(label)\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "output = model_test_printer(img)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e1dae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the flatten input into a csv\n",
    "in_flatten = flatten_x.cpu().detach().numpy()\n",
    "\n",
    "df_in_flatten = pd.DataFrame(in_flatten)\n",
    "#Export to csv with pandas \n",
    "df_in_flatten.to_csv('input_image_flatten.csv',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1002fa",
   "metadata": {},
   "source": [
    "# Testing the multiplications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb44e9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of flatten input torch.Size([1, 784])\n",
      "------------layer 1-----------\n",
      "shape weight fc1 torch.Size([100, 784])\n",
      "shape of fc1 output torch.Size([1, 100])\n",
      "shape of fc1 signed output torch.Size([1, 100])\n",
      "------------layer 2-----------\n",
      "shape weight fc2 torch.Size([100, 100])\n",
      "shape of fc2 output torch.Size([1, 100])\n",
      "shape of fc2 signed output torch.Size([1, 100])\n",
      "------------layer 3-----------\n",
      "shape weight fc3 torch.Size([100, 100])\n",
      "shape of fc3 output torch.Size([1, 100])\n",
      "shape of fc3 signed output torch.Size([1, 100])\n",
      "shape of output torch.Size([1, 10])\n",
      "------------layer 4-----------\n",
      "shape weight fc4 torch.Size([10, 100])\n",
      "shape of fc4 output torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# the output of the first layer should be the flattened input vector times the weight matrix of first layer\n",
    "# lets first see the shapes of these two \n",
    "# size returns (row,column)\n",
    "\n",
    "print(\"shape of flatten input\",flatten_x.shape )\n",
    "print(\"------------layer 1-----------\") \n",
    "print(\"shape weight fc1\",model_test_printer.fc1.weight.shape)\n",
    "print(\"shape of fc1 output\",fc1_out.shape)\n",
    "print(\"shape of fc1 signed output\",signed_fc1_out.shape)\n",
    "print(\"------------layer 2-----------\") \n",
    "print(\"shape weight fc2\",model_test_printer.fc2.weight.shape)\n",
    "print(\"shape of fc2 output\",fc2_out.shape)\n",
    "print(\"shape of fc2 signed output\",signed_fc2_out.shape)\n",
    "print(\"------------layer 3-----------\") \n",
    "print(\"shape weight fc3\",model_test_printer.fc3.weight.shape)\n",
    "print(\"shape of fc3 output\",fc3_out.shape)\n",
    "print(\"shape of fc3 signed output\",signed_fc3_out.shape)\n",
    "print(\"shape of output\",fc4_out.shape )\n",
    "print(\"------------layer 4-----------\") \n",
    "print(\"shape weight fc4\",model_test_printer.fc4.weight.shape)\n",
    "print(\"shape of fc4 output\",fc4_out.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca9294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am now going to verify the operations one by one to make sure dimensions are corrects and also results \n",
    "\n",
    "#LAYER 1 -> sing(flatten_x*fc1.weightT)\n",
    "fc1_out_mine = my_sign(torch.matmul(flatten_x,torch.transpose(model_test_printer.fc1.weight,1,0)))\n",
    "print(\"layer 1 op is: \",torch.all(fc1_out_mine.eq(signed_fc1_out)))\n",
    "\n",
    "#LAYER 2 -> sing(fc1_out_mine*fc2.weightT)\n",
    "fc2_out_mine = my_sign(torch.matmul(fc1_out_mine,torch.transpose(model_test_printer.fc2.weight,1,0)))\n",
    "print(\"layer 2 op is: \",torch.all(fc2_out_mine.eq(signed_fc2_out)))\n",
    "\n",
    "#LAYER 3 -> sing(fc2_out_mine*fc3.weightT)\n",
    "fc3_out_mine = my_sign(torch.matmul(fc2_out_mine,torch.transpose(model_test_printer.fc3.weight,1,0)))\n",
    "print(\"layer 3 op is: \",torch.all(fc3_out_mine.eq(signed_fc3_out)))\n",
    "\n",
    "#LAYER 3 (output) -> fc3_out_mine*fc4.weightT\n",
    "fc4_out_mine = torch.matmul(fc3_out_mine,torch.transpose(model_test_printer.fc4.weight,1,0))\n",
    "print(\"output op is: \",torch.all(fc4_out_mine.eq(fc4_out)))\n",
    "\n",
    "print(\"my output tensor: \",fc4_out_mine )\n",
    "print(\"network output tensor: \",fc4_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
