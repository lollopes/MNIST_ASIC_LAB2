{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bcda493",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "\n",
    "In the following block we are just importing the main libraries used for creating a NN and processing its output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d89f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from models.binarized_modules import  BinarizeLinear,BinarizeConv2d\n",
    "from models.binarized_modules import  Binarize,HingeLoss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85a310",
   "metadata": {},
   "source": [
    "# Load MNIST\n",
    "\n",
    "In the incoming block the MNIST dataset is created and loaded to the standard DataLoader of pytorch. This allow to simply call train_data and test_data when training the network without having to manually create the batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13219a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdTransform(object):\n",
    "    def __init__(self, thr_255):\n",
    "        self.thr = thr_255   # input threshold for [0..255] gray level, convert to [0..1]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x[x >= 0] = 1\n",
    "        x[x <= 0] = 0\n",
    "        \n",
    "        return x  # do not change the data type\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76648145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "          1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data: convert to tensors and normalize by subtracting dataset\n",
    "# mean and dividing by std.\n",
    "# We need to recall that the data is normalized when doing the ASIC implementation \n",
    "# The dummy input we feed in the ASIC must be normalized as well \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                ThresholdTransform(thr_255=0)])\n",
    "\n",
    "#transforms.Resize((2,2)),\n",
    "\n",
    "# Get data from torchvision.datasets\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# Define data loaders used to iterate through dataset\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data)\n",
    "\n",
    "\n",
    "\n",
    "# Show some example images and the associated label to verify that the data is loaded correctly \n",
    "\n",
    "labels_map = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9 Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 10, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "imgt, labelt = test_data[0]\n",
    "print(imgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c37c7",
   "metadata": {},
   "source": [
    "# MNIST classification with Binary Neural Network\n",
    "## Sign function \n",
    "The function implemented below is the sign() function mentioned in the paper. However, this function is not used for training as it would not allow for gradient descent calculation. The idea is to use this function after the train has been performed (TODO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859b14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sign(a):\n",
    "    \n",
    "    a_buff = torch.empty(a.shape)\n",
    "    for idx, element in enumerate(a):\n",
    "        for idy, sub_element in enumerate(element):\n",
    "            if(sub_element >= 0):\n",
    "                a_buff[idx][idy] = 1\n",
    "            else:\n",
    "                a_buff[idx][idy] = -1\n",
    "            \n",
    "    return a_buff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33abfde",
   "metadata": {},
   "source": [
    "## Create a class for the pytorch BNN\n",
    "Here I am basically creating my own definition of the network, the __init__ is the constructor and creates the class instances of the layer I want to use. The foreward function instead, perform the foreward pass of the network based on the order on which I put the layers previously created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7840a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_BNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(MY_BNN, self).__init__()\n",
    "        self.fc1 = BinarizeLinear(in_features, hidden_dim, bias = False)\n",
    "        self.htanh1 = nn.Hardtanh()\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.htanh2 = nn.Hardtanh()\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.htanh3 = nn.Hardtanh()\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc4 = BinarizeLinear(hidden_dim, out_features, bias = False)\n",
    "        self.drop=nn.Dropout(0.25)\n",
    "        self.logsoftmax=nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)    \n",
    "        x = self.bn1(x)    \n",
    "        x = self.htanh1(x) \n",
    "        x = self.fc2(x)    \n",
    "        x = self.bn2(x)    \n",
    "        x = self.htanh2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.htanh3(x)\n",
    "        x = self.fc4(x)\n",
    "        #x = self.htanh3(x)\n",
    "        return self.logsoftmax(x)\n",
    "        #return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f218dfe",
   "metadata": {},
   "source": [
    "## Initialize parameters and criterion of the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23336d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bytes required 0.0125 Mbyte\n"
     ]
    }
   ],
   "source": [
    "# Initialize Pytorch network\n",
    "\n",
    "in_features = 28*28 # this is because the input image is flatten into and array of 28*28, 28 being the number of pixels\n",
    "hidden_dim = 100 # number of neurons in an hidden layer\n",
    "hidden_layers = 4\n",
    "out_features = 10 # we need to classify 10 classes of number 0 to 10 \n",
    "learning_rate = 0.003 # this is the step that we take to move in the direction of the gradient \n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Meaning that we use cross entropy as a loss function \n",
    "epochs = 10 # number of times we are going across the full dataset \n",
    "\n",
    "\n",
    "\n",
    "model = MY_BNN(in_features, hidden_dim, out_features)\n",
    "\n",
    "#find number of param \n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of bytes required\",pytorch_total_params /8/1e6 , \"Mbyte\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate) # Adam algorithm to optimize change of learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e9e8b",
   "metadata": {},
   "source": [
    "## Definition of the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e4ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []  # hold the loss for each batch -> used to display training afterwards \n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "\n",
    "        if epoch%40==0:\n",
    "            optimizer.param_groups[0]['lr']=optimizer.param_groups[0]['lr']*0.1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in list(model.parameters()):\n",
    "            #print(\"inside for\")\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "        optimizer.step()\n",
    "        for p in list(model.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "                \n",
    "        #print(output)\n",
    "        #print(target)\n",
    "       # correct = torch.argmax(output, axis=1) == torch.argmax(target, axis=1)\n",
    "        #train_accs.append(torch.sum(correct)/len(y_pred))\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    train_losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.bn2.weight\n",
    "for p in list(model.parameters()):\n",
    "    print(p.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5775fe",
   "metadata": {},
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fbbd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/j0yzvf055y7c23h6ltl5b3pr0000gn/T/ipykernel_82168/4020480207.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.logsoftmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 14.967752\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 3.314790\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.034814\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.846137\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.116923\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.709789\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.268419\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.156369\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.674825\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.461180\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.864107\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 3.047797\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.725594\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.377731\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.481951\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.251547\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.868512\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 3.529536\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.438846\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.476863\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.381366\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.678556\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.684314\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.127827\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.874271\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.783508\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.111599\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.339494\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.415029\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 2.820764\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.100588\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.408951\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 2.151289\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.705750\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.166929\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 2.157688\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.858652\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 2.249607\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 3.100980\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.689652\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.716451\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 2.290538\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.681577\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 2.330959\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.419963\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.154122\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.863212\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.920375\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.695943\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.252423\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.854749\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.480314\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.988461\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 2.475694\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.280323\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.294359\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.325100\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.894060\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 3.041203\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 1.130626\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.440591\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.959950\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.872412\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 1.418758\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.606758\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.490705\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.918094\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 2.207731\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.692450\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 1.982465\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.081012\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 1.350629\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 2.230774\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 1.954043\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.248769\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.689242\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.569442\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.321191\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.047309\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.998870\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.879897\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.643712\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.536496\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.749476\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.729989\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 2.289062\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.077701\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.891877\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 2.000588\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 1.226819\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.973284\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 3.185436\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.455748\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 1.008676\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.657454\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.692759\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.381965\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 1.076774\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.568868\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.438529\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f06a4",
   "metadata": {},
   "source": [
    "## Display loss vs iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d16dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "for element in train_losses:\n",
    "    new.append(element.detach().numpy())\n",
    "    \n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(new)\n",
    "plt.grid()\n",
    "plt.savefig('foo.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b874b15",
   "metadata": {},
   "source": [
    "## Define a function for testing the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96c8727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "       \n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d854a31",
   "metadata": {},
   "source": [
    "## Test it\n",
    "After this section the accuracy of the trained network will be printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f978be86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/j0yzvf055y7c23h6ltl5b3pr0000gn/T/ipykernel_82168/4020480207.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.logsoftmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.1293, Accuracy: 9365/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf9a8a",
   "metadata": {},
   "source": [
    "## Test a single prediction after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cf24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_data[1]\n",
    "print(label)\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "output = model(img)\n",
    "print(output)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d93d47a",
   "metadata": {},
   "source": [
    "## Printing the weights\n",
    "This section must be refined to make sure that I am able to print the weight for each layer in a proper manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea45a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc2.weight)\n",
    "print(model.fc2.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c4b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight)\n",
    "print(model.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc3.weight.shape)\n",
    "print(model.fc3.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ac8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc4.weight)\n",
    "print(model.fc4.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb91a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.bn1.weight)\n",
    "print(model.fc4.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf49ab4",
   "metadata": {},
   "source": [
    "## Save network weights in a csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98aec9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First convert all network layers into numpy \n",
    "numpy_fc1 = model.fc1.weight.data.cpu().detach().numpy()\n",
    "numpy_fc2 = model.fc2.weight.data.cpu().detach().numpy()\n",
    "numpy_fc3 = model.fc3.weight.data.cpu().detach().numpy()\n",
    "numpy_fc4 = model.fc4.weight.data.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "#Convert numpy to pandas dataframe \n",
    "df_fc1 = pd.DataFrame(numpy_fc1).astype(int)\n",
    "df_fc2 = pd.DataFrame(numpy_fc2).astype(int)\n",
    "df_fc3 = pd.DataFrame(numpy_fc3).astype(int)\n",
    "df_fc4 = pd.DataFrame(numpy_fc4).astype(int)\n",
    "\n",
    "df_fc1[:] = df_fc1[:].replace([-1],0)\n",
    "df_fc2[:] = df_fc2[:].replace([-1],0)\n",
    "df_fc3[:] = df_fc3[:].replace([-1],0)\n",
    "df_fc4[:] = df_fc4[:].replace([-1],0)\n",
    "\n",
    "\n",
    "\n",
    "#Export to csv with pandas \n",
    "df_fc1.to_csv('baseline/W_fc1.txt',index=False,header=False)\n",
    "df_fc2.to_csv('baseline/W_fc2.txt',index=False,header=False)\n",
    "df_fc3.to_csv('baseline/W_fc3.txt',index=False,header=False)\n",
    "df_fc4.to_csv('baseline/W_fc4.txt',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c9721",
   "metadata": {},
   "source": [
    "# Test binarized\n",
    "I know want to test if the network still infers correctly if I have the sign instead of the hardtanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9e9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_BNN_test(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(MY_BNN_test, self).__init__()\n",
    "\n",
    "        self.fc1 = BinarizeLinear(in_features, hidden_dim, bias = False)\n",
    "        self.fc2 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc3 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc4 = BinarizeLinear(hidden_dim, out_features, bias = False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"in fws\")\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc2(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc3(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc4(x)\n",
    "        #x = my_sign(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea60ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = MY_BNN_test(in_features, hidden_dim, out_features)\n",
    "model_test.fc1.weight = model.fc1.weight\n",
    "model_test.fc2.weight = model.fc2.weight\n",
    "model_test.fc3.weight = model.fc3.weight\n",
    "model_test.fc4.weight = model.fc4.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c23a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_test.fc1.weight.shape)\n",
    "print(model_test.fc2.weight.shape)\n",
    "print(model_test.fc3.weight.shape)\n",
    "print(model_test.fc4.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d7dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_test():\n",
    "    model_test.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            #print(data)\n",
    "            output = model_test(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb36477",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a49f3",
   "metadata": {},
   "source": [
    "# Testing that outputs are binarized values at each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c7f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a model that prints the output tensor at each stage \n",
    "\n",
    "class MY_BNN_test_printer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_dim, out_features):\n",
    "        super(MY_BNN_test_printer, self).__init__()\n",
    "\n",
    "        self.fc1 = BinarizeLinear(in_features, hidden_dim, bias = False)\n",
    "        self.fc2 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc3 = BinarizeLinear(hidden_dim, hidden_dim, bias = False)\n",
    "        self.fc4 = BinarizeLinear(hidden_dim, out_features, bias = False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        global flatten_x,fc1_out,signed_fc1_out,fc2_out,signed_fc2_out,fc3_out,signed_fc3_out,fc4_out\n",
    "        x = x.view(-1, 28*28)\n",
    "        flatten_x = x\n",
    "        x = self.fc1(x)\n",
    "        fc1_out = x\n",
    "        x = my_sign(x)\n",
    "        signed_fc1_out = x\n",
    "        x = self.fc2(x)\n",
    "        fc2_out = x\n",
    "        x = my_sign(x)\n",
    "        signed_fc2_out = x\n",
    "        x = self.fc3(x)\n",
    "        fc3_out = x\n",
    "        x = my_sign(x)\n",
    "        signed_fc3_out = x\n",
    "        x = self.fc4(x)\n",
    "        fc4_out = x\n",
    "        return fc4_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411c65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_printer = MY_BNN_test_printer(in_features, hidden_dim, out_features)\n",
    "model_test_printer.fc1.weight = model.fc1.weight\n",
    "model_test_printer.fc2.weight = model.fc2.weight\n",
    "model_test_printer.fc3.weight = model.fc3.weight\n",
    "model_test_printer.fc4.weight = model.fc4.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9607eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_test_printer.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e780707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([[ 0., 32.,  8.,  6., -2., 10.,  2., -8., 40.,  4.]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "tensor([[8]])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#just getting one image to feed in the network\n",
    "\n",
    "img, label = test_data[2]\n",
    "print(label)\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "output = model_test_printer(img)\n",
    "print(output)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "print(pred)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e1dae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the flatten input into a csv\n",
    "in_flatten = flatten_x.cpu().detach().numpy()\n",
    "\n",
    "df_in_flatten = pd.DataFrame(in_flatten).astype(int)\n",
    "\n",
    "#Export to csv with pandas \n",
    "df_in_flatten.to_csv('baseline/input_number_4_output_8.txt',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1002fa",
   "metadata": {},
   "source": [
    "# Testing the multiplications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of the first layer should be the flattened input vector times the weight matrix of first layer\n",
    "# lets first see the shapes of these two \n",
    "# size returns (row,column)\n",
    "\n",
    "print(\"shape of flatten input\",flatten_x.shape )\n",
    "print(\"------------layer 1-----------\") \n",
    "print(\"shape weight fc1\",model_test_printer.fc1.weight.shape)\n",
    "print(\"shape of fc1 output\",fc1_out.shape)\n",
    "print(\"shape of fc1 signed output\",signed_fc1_out.shape)\n",
    "print(\"------------layer 2-----------\") \n",
    "print(\"shape weight fc2\",model_test_printer.fc2.weight.shape)\n",
    "print(\"shape of fc2 output\",fc2_out.shape)\n",
    "print(\"shape of fc2 signed output\",signed_fc2_out.shape)\n",
    "print(\"------------layer 3-----------\") \n",
    "print(\"shape weight fc3\",model_test_printer.fc3.weight.shape)\n",
    "print(\"shape of fc3 output\",fc3_out.shape)\n",
    "print(\"shape of fc3 signed output\",signed_fc3_out.shape)\n",
    "print(\"shape of output\",fc4_out.shape )\n",
    "print(\"------------layer 4-----------\") \n",
    "print(\"shape weight fc4\",model_test_printer.fc4.weight.shape)\n",
    "print(\"shape of fc4 output\",fc4_out.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fca9294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 op is:  tensor(True)\n",
      "layer 2 op is:  tensor(True)\n",
      "layer 3 op is:  tensor(True)\n",
      "output op is:  tensor(True)\n",
      "my output tensor:  tensor([[ -2., -18., -10.,   4., -20.,  16., -20.,  18., -10.,  14.]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "network output tensor:  tensor([[ -2., -18., -10.,   4., -20.,  16., -20.,  18., -10.,  14.]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#I am now going to verify the operations one by one to make sure dimensions are corrects and also results \n",
    "\n",
    "#LAYER 1 -> sing(flatten_x*fc1.weightT)\n",
    "fc1_out_mine = my_sign(torch.matmul(flatten_x,torch.transpose(model_test_printer.fc1.weight,1,0)))\n",
    "print(\"layer 1 op is: \",torch.all(fc1_out_mine.eq(signed_fc1_out)))\n",
    "\n",
    "#save the output of LAYER 1\n",
    "#Convert the flatten input into a csv\n",
    "out_1= signed_fc1_out.cpu().detach().numpy()\n",
    "out_1_d = pd.DataFrame(out_1).astype(int)\n",
    "out_1_d[:] = out_1_d[:].replace([-1],0)\n",
    "out_1_d.to_csv('baseline/layer_1_out.txt',index=False,header=False)\n",
    "\n",
    "#LAYER 2 -> sing(fc1_out_mine*fc2.weightT)\n",
    "fc2_out_mine = my_sign(torch.matmul(fc1_out_mine,torch.transpose(model_test_printer.fc2.weight,1,0)))\n",
    "print(\"layer 2 op is: \",torch.all(fc2_out_mine.eq(signed_fc2_out)))\n",
    "\n",
    "#save the output of LAYER 2 \n",
    "#Convert the flatten input into a csv\n",
    "out_2= signed_fc2_out.cpu().detach().numpy()\n",
    "out_2_d = pd.DataFrame(out_2).astype(int)\n",
    "out_2_d[:] = out_2_d[:].replace([-1],0)\n",
    "out_2_d.to_csv('baseline/layer_2_out.txt',index=False,header=False)\n",
    "\n",
    "#LAYER 3 -> sing(fc2_out_mine*fc3.weightT)\n",
    "fc3_out_mine = my_sign(torch.matmul(fc2_out_mine,torch.transpose(model_test_printer.fc3.weight,1,0)))\n",
    "print(\"layer 3 op is: \",torch.all(fc3_out_mine.eq(signed_fc3_out)))\n",
    "\n",
    "#save the output of LAYER 3 \n",
    "#Convert the flatten input into a csv\n",
    "out_3= signed_fc3_out.cpu().detach().numpy()\n",
    "out_3_d = pd.DataFrame(out_3).astype(int)\n",
    "out_3_d[:] = out_3_d[:].replace([-1],0)\n",
    "out_3_d.to_csv('baseline/layer_3_out.txt',index=False,header=False)\n",
    "\n",
    "#LAYER 4 (output) -> fc3_out_mine*fc4.weightT\n",
    "fc4_out_mine = torch.matmul(fc3_out_mine,torch.transpose(model_test_printer.fc4.weight,1,0))\n",
    "print(\"output op is: \",torch.all(fc4_out_mine.eq(fc4_out)))\n",
    "\n",
    "#save the output of LAYER 4\n",
    "#Convert the flatten input into a csv\n",
    "out_4= fc4_out.cpu().detach().numpy()\n",
    "out_4_d = pd.DataFrame(out_4).astype(int)\n",
    "out_4_d.to_csv('baseline/output.txt',index=False,header=False)\n",
    "\n",
    "print(\"my output tensor: \",fc4_out_mine )\n",
    "print(\"network output tensor: \",fc4_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0,1,1,0,1,0,1,0,0,0,0,0,0,0,1,1,1,0,1,1,1,0,1,1,0,1,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,1,1,1,1,0,0,0,1,0,0,0,0,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,0,0,0,1,1,0,0,1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,0,0,0,0,0,0,0,1,0,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,0,1,1,1,1,1,1,1,0,0,1,0,1,1,0,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1,1,1,1,1,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,1,1,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,1,1,1,0,1,1,0,1,0,1,0,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,1,1,1,1,1,0,0,1,1,1,1,0,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,1,1,1,1,0,1,1,1,1,0,0,0,0,0,1,1,0,0,1,1,1,0,0,0,0,0,0,0,1,1,1,0,1,1,1,1,1,0,0,0,0,0,0,1,1,1,0,1,1,0,0,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,1,1,1,1,0,1,1,1,1,1,1,0,0,1,1,1,1,1,0,1,1,1,1,1,0,0,0,1,0,0,1,0,1,0,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,1,1,1,1,0,1,1,0,1,1,1,1,0,1,1,1,0,0,0,0,0,0,1,0,1,1,1,0,1,1,0,1,1,0,1,0,0,1,0,1,0,1,1,1,1,0,0,0,0,1,0,1,1,1,0,1,1,1,0,0,1,0,0,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,0,1,1,1,1,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,0,0,1,1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1,1,1,1,1,0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1,1,0,0,1,0,1,0,0,1,1,1,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,1,1]\n",
    "y = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53371a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(x)):\n",
    "    sum = sum + x[i]*y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "hah =torch.matmul(flatten_x,torch.transpose(model_test_printer.fc1.weight,1,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b396a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sign(hah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_x,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=200)\n",
    "g = torch.transpose(model_test_printer.fc1.weight,1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc3e8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
