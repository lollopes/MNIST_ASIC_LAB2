{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38864178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from models.binarized_modules import  BinarizeLinear,BinarizeConv2d\n",
    "from models.binarized_modules import  Binarize,HingeLoss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66c3e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "          1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "class ThresholdTransform(object):\n",
    "    def __init__(self, thr_255):\n",
    "        self.thr = thr_255   # input threshold for [0..255] gray level, convert to [0..1]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x[x >= 0] = 1\n",
    "        x[x <= 0] = 0      \n",
    "        return x  \n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                ThresholdTransform(thr_255=0)])\n",
    "\n",
    "\n",
    "# Get data from torchvision.datasets\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define data loaders used to iterate through dataset\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data)\n",
    "\n",
    "# Show some example images and the associated label to verify that the data is loaded correctly \n",
    "\n",
    "labels_map = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9 Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 10, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "imgt, labelt = test_data[0]\n",
    "print(imgt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0d16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_SW(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features = 28*28, HL_1=100, HL_2=100, HL_3=100, out_features=10):\n",
    "        super(BNN_SW, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.fc1 = BinarizeLinear(in_features, HL_1, bias = False)\n",
    "        self.htanh1 = nn.Hardtanh()\n",
    "        self.bn1 = nn.BatchNorm1d(HL_1)\n",
    "        self.fc2 = BinarizeLinear(HL_1, HL_2, bias = False)\n",
    "        self.htanh2 = nn.Hardtanh()\n",
    "        self.bn2 = nn.BatchNorm1d(HL_2)\n",
    "        self.fc3 = BinarizeLinear(HL_2, HL_3, bias = False)\n",
    "        self.htanh3 = nn.Hardtanh()\n",
    "        self.bn3 = nn.BatchNorm1d(HL_3)\n",
    "        self.fc4 = BinarizeLinear(HL_3, out_features, bias = False)\n",
    "        self.drop=nn.Dropout(0.25)\n",
    "        self.logsoftmax=nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.in_features)\n",
    "        x = self.fc1(x)    \n",
    "        x = self.bn1(x)    \n",
    "        x = self.htanh1(x) \n",
    "        x = self.fc2(x)    \n",
    "        x = self.bn2(x)    \n",
    "        x = self.htanh2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.htanh3(x)\n",
    "        x = self.fc4(x)\n",
    "        return self.logsoftmax(x)\n",
    "\n",
    "class BNN_HW(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features = 28*28, HL_1=100, HL_2=100, HL_3=100, out_features=10):\n",
    "        super(BNN_HW, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.fc1 = BinarizeLinear(in_features, HL_1, bias = False)\n",
    "        self.fc2 = BinarizeLinear(HL_1, HL_2, bias = False)\n",
    "        self.fc3 = BinarizeLinear(HL_2, HL_3, bias = False)\n",
    "        self.fc4 = BinarizeLinear(HL_3, out_features, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.in_features)\n",
    "        x = self.fc1(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc2(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc3(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d94c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model_hw,space_idx,learning_rate):\n",
    "    \n",
    "    #print(\"space: \\n\",space)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_hw.parameters(), learning_rate) # Adam algorithm to optimize change of learning_rate\n",
    "\n",
    "\n",
    "    model_hw.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_hw(data)\n",
    "        #print(\"shape is \",data.shape)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if epoch%40==0:\n",
    "            optimizer.param_groups[0]['lr']=optimizer.param_groups[0]['lr']*0.1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in list(model_hw.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "        optimizer.step()\n",
    "        for p in list(model_hw.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "        \n",
    "        \n",
    "    #print('Train Epoch: {} Space_idx {}/{} Space {} \\tLoss: {:.6f}'.format(\n",
    "                #epoch, space_idx, space_dim, space, loss.item()))\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53a285a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sign(a):\n",
    "    \n",
    "    a_buff = torch.empty(a.shape)\n",
    "    for idx, element in enumerate(a):\n",
    "        for idy, sub_element in enumerate(element):\n",
    "            if(sub_element >= 0):\n",
    "                a_buff[idx][idy] = 1\n",
    "            else:\n",
    "                a_buff[idx][idy] = -1\n",
    "            \n",
    "    return a_buff\n",
    "\n",
    "\n",
    "def test_sw(model):\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "       \n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def test_hw(model):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            #print(data)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eebaf0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 32, 32, 0.003), (64, 32, 32, 0.003)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8f/j0yzvf055y7c23h6ltl5b3pr0000gn/T/ipykernel_57384/3095798551.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.logsoftmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 0.003) space 0/1 HW_acc: tensor(54.4900) SW_acc: tensor(80.4800)\n",
      "(64, 32, 32, 0.003) space 1/1 HW_acc: tensor(60.1800) SW_acc: tensor(83.9700)\n"
     ]
    }
   ],
   "source": [
    "# Create a search space for the layer size \n",
    "\n",
    "res = []\n",
    "\n",
    "HL_1 = [32, 64]\n",
    "HL_2 = [32]\n",
    "HL_3 = [32]\n",
    "LR = [0.003]\n",
    "\n",
    "search_space = []\n",
    "import itertools\n",
    "\n",
    "#search_space[layer1.layer2,layer3,LR]\n",
    "for r in itertools.product(HL_1,HL_2,HL_3,LR): search_space.append((r[0],r[1],r[2],r[3]))\n",
    "\n",
    "print(search_space)\n",
    "# Outer loop with the search space\n",
    "for space_idx, space in enumerate(search_space):\n",
    "    \n",
    "    model_sw = BNN_SW(in_features = IMAGE_SIZE*IMAGE_SIZE,\n",
    "                      HL_1 = space[0],\n",
    "                      HL_2 = space[1],\n",
    "                      HL_3 = space[2])\n",
    "    \n",
    "    model_hw = BNN_HW(in_features = IMAGE_SIZE*IMAGE_SIZE,\n",
    "                      HL_1 = space[0],\n",
    "                      HL_2 = space[1],\n",
    "                      HL_3 = space[2])\n",
    "    \n",
    "    # Inner loop for epochs \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(epoch,model_sw,space_idx,space[3])\n",
    "    \n",
    "    accuracy_sw = test_sw(model_sw)\n",
    "    \n",
    "    model_hw.fc1.weight = model_sw.fc1.weight\n",
    "    model_hw.fc2.weight = model_sw.fc2.weight\n",
    "    model_hw.fc3.weight = model_sw.fc3.weight\n",
    "    model_hw.fc4.weight = model_sw.fc4.weight\n",
    "       \n",
    "    accuracy_hw = test_hw(model_hw)\n",
    "    \n",
    "    print(space,'space {}/{}'.format(space_idx,len(search_space)-1),\"HW_acc:\",accuracy_hw,\"SW_acc:\",accuracy_sw)\n",
    "    res.append(((space),accuracy_sw.item(),accuracy_hw.item()))\n",
    "    \n",
    "    del model_sw\n",
    "    del model_hw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab3e6d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((32, 32, 32, 0.003), 80.4800033569336, 54.4900016784668),\n",
       " ((64, 32, 32, 0.003), 83.97000122070312, 60.18000030517578)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(x, 10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d5ae62f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3e220a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (5, 5, 5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_LOSS = []\n",
    "TRAIN_LOSS.append((1,2,3))\n",
    "TRAIN_LOSS.append((5,5,5))\n",
    "TRAIN_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb323737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
