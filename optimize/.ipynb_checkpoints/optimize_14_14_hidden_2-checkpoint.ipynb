{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c668698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from models.binarized_modules import  BinarizeLinear,BinarizeConv2d\n",
    "from models.binarized_modules import  Binarize,HingeLoss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83698b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "          1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
      "          1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 14\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2\n",
    "\n",
    "\n",
    "class ThresholdTransform(object):\n",
    "    def __init__(self, thr_255):\n",
    "        self.thr = thr_255   # input threshold for [0..255] gray level, convert to [0..1]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x[x >= 0] = 1\n",
    "        x[x <= 0] = 0      \n",
    "        return x  \n",
    "    \n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "                                ThresholdTransform(thr_255=0)])\n",
    "\n",
    "\n",
    "# Get data from torchvision.datasets\n",
    "train_data = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define data loaders used to iterate through dataset\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data)\n",
    "\n",
    "# Show some example images and the associated label to verify that the data is loaded correctly \n",
    "\n",
    "labels_map = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9 Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 10, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "imgt, labelt = test_data[0]\n",
    "print(imgt)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d3450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNN_SW(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features = 28*28, HL_1=100, HL_2=100, HL_3=100, out_features=10):\n",
    "        super(BNN_SW, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.fc1 = BinarizeLinear(in_features, HL_1, bias = False)\n",
    "        self.htanh1 = nn.Hardtanh()\n",
    "        self.bn1 = nn.BatchNorm1d(HL_1)\n",
    "        self.fc2 = BinarizeLinear(HL_1, HL_2, bias = False)\n",
    "        self.htanh2 = nn.Hardtanh()\n",
    "        self.bn2 = nn.BatchNorm1d(HL_2)\n",
    "        self.fc3 = BinarizeLinear(HL_2, HL_3, bias = False)\n",
    "        self.htanh3 = nn.Hardtanh()\n",
    "        self.bn3 = nn.BatchNorm1d(HL_3)\n",
    "        self.fc4 = BinarizeLinear(HL_3, out_features, bias = False)\n",
    "        self.drop=nn.Dropout(0.25)\n",
    "        self.logsoftmax=nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.in_features)\n",
    "        x = self.fc1(x)    \n",
    "        x = self.bn1(x)    \n",
    "        x = self.htanh1(x) \n",
    "        x = self.fc2(x)    \n",
    "        x = self.bn2(x)    \n",
    "        x = self.htanh2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.htanh3(x)\n",
    "        x = self.fc4(x)\n",
    "        return self.logsoftmax(x)\n",
    "\n",
    "class BNN_HW(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features = 28*28, HL_1=100, HL_2=100, HL_3=100, out_features=10):\n",
    "        super(BNN_HW, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.fc1 = BinarizeLinear(in_features, HL_1, bias = False)\n",
    "        self.fc2 = BinarizeLinear(HL_1, HL_2, bias = False)\n",
    "        self.fc3 = BinarizeLinear(HL_2, HL_3, bias = False)\n",
    "        self.fc4 = BinarizeLinear(HL_3, out_features, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.in_features)\n",
    "        x = self.fc1(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc2(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc3(x)\n",
    "        x = my_sign(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c867541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,model_hw,space_idx,learning_rate):\n",
    "    \n",
    "    #print(\"space: \\n\",space)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_hw.parameters(), learning_rate) # Adam algorithm to optimize change of learning_rate\n",
    "\n",
    "\n",
    "    model_hw.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_hw(data)\n",
    "        #print(\"shape is \",data.shape)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if epoch%40==0:\n",
    "            optimizer.param_groups[0]['lr']=optimizer.param_groups[0]['lr']*0.1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for p in list(model_hw.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.data.copy_(p.org)\n",
    "        optimizer.step()\n",
    "        for p in list(model_hw.parameters()):\n",
    "            if hasattr(p,'org'):\n",
    "                p.org.copy_(p.data.clamp_(-1,1))\n",
    "        \n",
    "        \n",
    "    #print('Train Epoch: {} Space_idx {}/{} Space {} \\tLoss: {:.6f}'.format(\n",
    "                #epoch, space_idx, space_dim, space, loss.item()))\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91f6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sign(a):\n",
    "    \n",
    "    a_buff = torch.empty(a.shape)\n",
    "    for idx, element in enumerate(a):\n",
    "        for idy, sub_element in enumerate(element):\n",
    "            if(sub_element >= 0):\n",
    "                a_buff[idx][idy] = 1\n",
    "            else:\n",
    "                a_buff[idx][idy] = -1\n",
    "            \n",
    "    return a_buff\n",
    "\n",
    "\n",
    "def test_sw(model):\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "       \n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def test_hw(model):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            #print(data)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb40805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]/var/folders/8f/j0yzvf055y7c23h6ltl5b3pr0000gn/T/ipykernel_45977/1406638745.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.logsoftmax(x)\n",
      " 10%|█████████████▌                                                                                                                         | 1/10 [00:24<03:42, 24.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Space_idx 0 Space (32, 32, 32) \tLoss: 2.537601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████████████████                                                                                                            | 2/10 [00:48<03:15, 24.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 Space_idx 0 Space (32, 32, 32) \tLoss: 3.135919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████████████████████▌                                                                                              | 3/10 [01:12<02:49, 24.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Space_idx 0 Space (32, 32, 32) \tLoss: 1.616288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [01:37<02:25, 24.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Space_idx 0 Space (32, 32, 32) \tLoss: 2.126681\n"
     ]
    }
   ],
   "source": [
    "# Create a search space for the layer size \n",
    "\n",
    "res = []\n",
    "\n",
    "HL_1 = [32, 64,128]\n",
    "HL_2 = [32,64,128]\n",
    "HL_3 = [32,64,128]\n",
    "LR = [0.003,0.002]\n",
    "\n",
    "search_space = []\n",
    "import itertools\n",
    "\n",
    "#search_space[layer1.layer2,layer3,LR]\n",
    "for r in itertools.product(HL_1,HL_2,HL_3,LR): search_space.append((r[0],r[1],r[2],r[3]))\n",
    "\n",
    "print(search_space)\n",
    "# Outer loop with the search space\n",
    "for space_idx, space in enumerate(search_space):\n",
    "    \n",
    "    model_sw = BNN_SW(in_features = IMAGE_SIZE*IMAGE_SIZE,\n",
    "                      HL_1 = space[0],\n",
    "                      HL_2 = space[1],\n",
    "                      HL_3 = space[2])\n",
    "    \n",
    "    model_hw = BNN_HW(in_features = IMAGE_SIZE*IMAGE_SIZE,\n",
    "                      HL_1 = space[0],\n",
    "                      HL_2 = space[1],\n",
    "                      HL_3 = space[2])\n",
    "    \n",
    "    # Inner loop for epochs \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(epoch,model_sw,space_idx,space[3])\n",
    "    \n",
    "    accuracy_sw = test_sw(model_sw)\n",
    "    \n",
    "    model_hw.fc1.weight = model_sw.fc1.weight\n",
    "    model_hw.fc2.weight = model_sw.fc2.weight\n",
    "    model_hw.fc3.weight = model_sw.fc3.weight\n",
    "    model_hw.fc4.weight = model_sw.fc4.weight\n",
    "       \n",
    "    accuracy_hw = test_hw(model_hw)\n",
    "    \n",
    "    print(space,'space {}/{}'.format(space_idx,len(search_space)-1),\"HW_acc:\",accuracy_hw,\"SW_acc:\",accuracy_sw)\n",
    "    res.append((space),accuracy_sw,accuracy_hw)\n",
    "    \n",
    "    del model_sw\n",
    "    del model_hw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a66d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LOSS = []\n",
    "TRAIN_LOSS.append((1,2,3))\n",
    "TRAIN_LOSS.append((5,5,5))\n",
    "TRAIN_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
